########################################################################
# This is the configuration file of GridPilot
#
# Sections:
#
# - GridPilot : contains general parameters
# - File transfer systems : information about the file transfer systems
# - - For each system defined in File transfer systems, a section is required
# - Databases : information about the database connection
# - - For each system defined in Databases, a section is required
# - Computing Systems : contains the list of computing systems
# - - For each system defined in section Computing Systems, a section is required
#
# All tags are case insensitive, and a text after a # is a comment (but \# is allowed)
#
# Main author:
#
# - Frederik ORELLANA (frederik.orellana@cern.ch)
#
# Contributors:
#
# - Cyril TOPFEL (cyril.topfel@lhep.unibe.ch)
# - Marco NIINIMAKI (marko.niinimaki@cern.ch)
# - Luc GOOSSENS (luc.goossens@cern.ch)
# - Vandy BERTEN (vandy.berten@cern.ch)
#
########################################################################

[GridPilot]

# Whether or not to display advanced menu items
advanced mode = no

# This name is used for field in jobDefinition tables ONLY if
# no name can be obtained from grid the certificate.
default user = firelord

# Path to images, certificates, about.
resources = /resources/

# Debug level ; 0 : all debugs are disabled, 3 : maximum.
# Notice that having a high debug level can have a big impact on performance.
debug = 0

# Name of skin to use. Possible values are: blue and clear
skin = blue

# How to display buttons: 0 - icon only, 1 - text only, 2 - icon and text
buttons display = 2

# Initial panels (tabs) displayed. The syntax is: db_name:table_name
initial panels = My_DB_Local:dataset

# File to store the history of the file browser.
browser history file = ~/.gridpilot_history.txt

# Default URL when downloading/replicating, use ~ for local homedir, e.g. ~/GridPilot/
# Remote gsiftp URLs are also supported, e.g. gsiftp://my.home.server/grid/users/user_name/
grid home url = ~/GridPilot/data/

# URLs of RTE catalogs. They are used by computing system plugins
# GridFactory and VMFork to populate the runtimeEnvironment table
# of the runtime databases. They can be http URLs or local paths.
runtime catalog URLs = http://www.gridfactory.org/rtes.xml

# URL of directory containing exported GridPilot applications
# (files with extension .gpa).
application store URL = https://www.gridpilot.dk/apps/

# Directory with runtime setup scripts.
runtime directory = ~/GridPilot/runtimeEnvironments

# Number of file records to diplay on files tabs (with previous/next buttons).
# Use -1 to show all files.
file rows = 500

# Web proxy host IP name or address.
proxy host = 
# Web proxy port number.
proxy port =

# List of preferred files servers when downloading/uploading.
preferred file servers = gsiftp://lscf.nbi.dk srm://se01-lcg.projects.cscs.ch *.dk *.de *.ch *.fr

# Number of threads checking job or transfer status.
max simultaneous checking = 3

# Start/default value of delay between automatic checks of jobs or transfers status
# - in milliseconds.
# This value is used when the "Refresh each" checkbox is checked.
time between checks = 500

# Confirm interruption of hanging threads.
ask before thread interrupt = yes

# Attributes always displayed when creating job definitions.
job attributes = number name eventMin eventMax nEvents

## Authentication
# Proxy type, can be one of OLD, GLOBUS, RFC.
# Notice that gLite only supports OLD, ARC both and GridFactory only RFC
# (GridFactory doesn't use proxies).
proxy type = OLD
# Number of seconds before timeout of proxy when proxy will be renewed.
proxy time left limit = 43200 # 12h
# Validity of proxy in seconds.
proxy time valid = 129600 # 36 h
# Location of X509 user key.
key file = ~/.globus/userkey.pem
# Encryption password for the X509 key.
# It is not recommended to set this, since this file is stored in plain-text.
key password = 
# Location of X509 user certificate.
certificate file = ~/.globus/usercert.pem
# Directory to store the X509 proxy.
proxy directory = ~/.globus
# A comma separated list of fully qualified file or directory paths.
# If this is left blank, the default certificates shipped with GridPilot will be used.
ca certificates = 
# File to use for caching CA certificates.
truststore file = ~/GridPilot/truststore.jks
# The name of the virtual organization under which jobs will run.
# Used for generating VOMS proxies and by GliteComputingSystem for the VirtualOrganisation tag in JDL.
# Notice that if this is not given or VOMS proxy generation fails for some other reason, a normal
# grid proxy will be attempted generated.
virtual organization = atlas
# IP name or address of VOMS server - optional; if not given a normal proxy is generated
voms server = https://lcg-voms.cern.ch:15001/DC=ch/DC=cern/OU=computers/CN=lcg-voms.cern.ch
# Path of VOMS directory. If this is left blank, the default VOMS definitions shipped with
# GridPilot will be used.
voms directory = ~/GridPilot/vomsdir
# VOMS fully qualified attribute name - optional
voms fqan = 

## Timeouts
# Values in seconds - 0 means wait forever
default timeout = 60
# Downloading and booting up a VM can take some time.
submit timeout = 720
updateStatus timeout = 120
killJob timeout = 60
clearOutputMapping timeout = 60
exit timeout = 70
getFullStatus timeout = 120
getCurrentOutputs timeout =  120
db timeout = 60

#####################################################################
[File transfer systems]
#
# File transfer systems used for replicating files.
#

# These are the supported systems. The names must match the protol names.
# NOTICE: always put subsystems before high-level systems, that is, always put srm last.
Systems = https gsiftp srm srm2 sss

# These ports must be inbound open in your firewall (comma-separated list).
globus tcp port range = 9001,9010

# Number of times to retry transfers.
copy retries = 0

# Timeout for copy attempts (in seconds)
copy retry timeout = 120

# Maximum number of running transfers. When this is reached,
# queued transfers will not be started until running transfers end.
max simultaneous running = 3
# Number of transfers to submitted in one go to each server.
max batch size = 1
# Delay between starting transfers in milliseconds.
time between transfers = 30000
# Whether to start transfers in the order they appear in the table or in random order.
randomized transfers = no

[https]
class = gridpilot.ftplugins.https.HTTPSFileTransfer
enabled = yes
# Number of transfers whose status is checked by each thread
# (see max simultaneous running).
max transfers by update = 3

[gsiftp]
class = gridpilot.ftplugins.gsiftp.GSIFTPFileTransfer
enabled = yes
# Number of transfers whose status is checked by each thread
# (see max simultaneous running).
max transfers by update = 3

[srm]
class = gridpilot.ftplugins.srm.SRMFileTransfer
enabled = yes
# Retries to get "Ready" on a submitted transfer, before timing out
submit check retries = 3
# Time between retries in miliseconds.
submit check sleep = 10000
# Number of transfers whose status is checked by each thread
# (see max simultaneous running).
max transfers by update = 1

[srm2]
class = gridpilot.ftplugins.srm.SRM2FileTransfer
enabled = yes
# Retries to get "Ready" on a submitted transfer, before timing out
submit check retries = 3
# Time between retries in miliseconds.
submit check sleep = 10000
# Number of transfers whose status is checked by each thread
# (see max simultaneous running).
max transfers by update = 1

[sss]
#
# The Simple Storage System (s3) offered by Amazon
#
class = gridpilot.ftplugins.sss.SSSFileTransfer
enabled = yes
# Number of transfers whose status is checked by each thread
# (see max simultaneous running).
max transfers by update = 1
# The access key id found on your AWS account web page
aws access key id = 
# The secret access key found on your AWS account web page
aws secret access key = 
# Whether or not to make uploaded files world readable
world readable files = no
# Whether or not to compress uploads
compress uploads = no
# Password for encrypting transferred files. If left empty, no encryption is done.
encryption password =
# Whether or not to use the convention of S3Fox for directories:
# If set to true, _$folder$ is appended to the name (both GridPilot and
# S3Fox suppres this string in the display).
# If set to false, nothing is appended and the content-type is simply
# set to x-directory. Unfortunately S3Fox does not use content-type.
s3fox directory mode = true

#####################################################################
[Databases]
#
# Databases used for storing runtime and executable
# informations as well as file and job information.
#

# NOTICE: use ONLY ONE local database at a time
Systems = My_DB_Local GP_DB Regional_DB My_DB_Remote ATLAS 

#--------------------------------------------------------------------
[My_DB_Local]
#
# Minimal dataset/job/file catalog for personal production/analysis.
#

class = gridpilot.dbplugins.hsqldb.HSQLDBDatabase
driver = org.hsqldb.jdbcDriver
database = hsql://localhost/~/GridPilot/My_DB
user = sa
password = ""

parameters = driver database user password

description = Local database
enabled = yes

default dataset fields = name outputLocation executableName identifier
hidden dataset fields = metaData
default jobDefinition fields = name status

dataset field names = identifier,                       name,                 executableName,   executableVersion, metaData,         runNumber,   totalFiles,  totalEvents, created,  lastModified, inputDataset,     inputDB,          outputLocation
dataset field types = LONGVARCHAR NOT NULL PRIMARY KEY, LONGVARCHAR NOT NULL, LONGVARCHAR NULL, LONGVARCHAR NULL,  LONGVARCHAR NULL, BIGINT NULL, BIGINT NULL, BIGINT NULL, DATETIME, DATETIME,     LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL

jobDefinition field names = identifier,                                           datasetName, name,        guid,        number, eventMin, eventMax, nEvents,  outputFileBytes, outputFileChecksum, cpuSeconds, status,       userInfo,    inputFileURLs, executableParameters, outFileMapping, host,        stdoutDest,  stderrDest,  created,  lastModified, jobID,             outTmp,             errTmp,             validationResult, computingSystem, csStatus,          metaData,         depJobs
jobDefinition field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, INT,    INT,      INT,      INT,      INT NULL,        VARCHAR(255),       INT NULL,   VARCHAR(255), LONGVARCHAR, LONGVARCHAR,   LONGVARCHAR,          LONGVARCHAR,    LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(1024) NULL, VARCHAR(1024) NULL, LONGVARCHAR NULL, VARCHAR NULL,    VARCHAR(255) NULL, LONGVARCHAR NULL, LONGVARCHAR NULL

executable field names = identifier, name, version, runtimeEnvironmentName, arguments, outputFiles, executableFile, comment, created, lastModified, inputFiles
executable field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, VARCHAR(255), LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME, LONGVARCHAR

runtimeEnvironment field names = identifier, name, computingSystem, certificate, url, initLines, depends, provides, created, lastModified
runtimeEnvironment field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME

# This is to have a pseudo catalog with file records generated on the fly from job definitions

#default file fields = datasetName name url identifier
#file identifier = identifier
#file name = name
#file dataset reference = name datasetName

# This is to have an explicit file catalog in three tables.

default file fields = dsname lfname pfname guid
file identifier = guid
file name = lfname
file dataset reference = name dsname
# The field on the displayed file table, containing the PFN(s)
pfns field = pfname
bytes field = fsize
checksum field = md5sum

file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid

t_lfn field names = lfname, guid
t_lfn field types = LONGVARCHAR, VARCHAR(255) PRIMARY KEY

t_pfn field names = pfname, guid, filetype
t_pfn field types = LONGVARCHAR, VARCHAR(255) PRIMARY KEY, LONGVARCHAR NULL

t_meta field names = guid, md5sum, fsize, lastmodified, archival, dsname
t_meta field types = VARCHAR(255) PRIMARY KEY, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, VARCHAR(255)

# This is to have an explicit file catalog in one table. Better performance

#default file fields = dsname lfname pfname guid
#file identifier = guid
#file name = lfname
#file dataset reference = name dsname
# The field on the displayed file table, containing the PFN(s)
#pfns field = pfname
#bytes field = fsize
#checksum field = md5sum

#file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid
#file field types = LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, VARCHAR(255), VARCHAR(255)

#--------------------------------------------------------------------
[My_DB_Remote]
#
# Minimal dataset/job catalog for personal production/analysis
# The database and user name are deduced from the user certificate.
# The authentication is also done with the user certificate.
# An explicit file catalog should not be needed.
#

class = gridpilot.dbplugins.mysql.MySQLDatabase
driver = org.gjt.mm.mysql.Driver
database = jdbc:mysql://my.home.server:3306/

parameters = driver database user password

description = Remote personal database
enabled = no

# JDBC connect timeouts in milliseconds; 0 means no timeout
connect timeout = 0
# JDBC socket timeouts in milliseconds; 0 means no timeout
socket timeout = 0

# Whether or not to cache search results locally
cache search results = yes

default dataset fields = name outputLocation executableName identifier
hidden dataset fields = metaData
default jobDefinition fields = name status
default file fields = name datasetName url identifier
file identifier = identifier
file name = name
file dataset reference = name datasetName

# NOTICE: semi-colon will be replaced with comma after parsing the fields

dataset field names = identifier,                   name,                                     executableName,    executableVersion, metaData,  runNumber,    totalFiles,   totalEvents,  created,  lastModified, inputDataset,      inputDB,           outputLocation
dataset field types = VARCHAR(255) NOT NULL UNIQUE, VARCHAR(255) NOT NULL UNIQUE PRIMARY KEY, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, INT(20) NULL, INT(20) NULL, INT(20) NULL, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL

jobDefinition field names = identifier, datasetName, name, guid, number, eventMin, eventMax, nEvents, outputFileBytes, outputFileChecksum, cpuSeconds, status, userInfo, inputFileURLs, executableParameters, outFileMapping, host, stdoutDest, stderrDest, created, lastModified, jobID, outTmp, errTmp, validationResult, computingSystem, csStatus, metaData, depJobs
jobDefinition field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), VARCHAR(255), INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, VARCHAR(255), INT(16) NULL, ENUM('Defined'; 'Submitted'; 'Validated'; 'Failed'; 'Undecided'; 'Aborted') NULL, VARCHAR(255), TEXT, VARCHAR(255), VARCHAR(2048), VARCHAR(255), VARCHAR(255), VARCHAR(255), DATETIME, DATETIME, VARCHAR(255) NULL, VARCHAR(1024) NULL, VARCHAR(1024) NULL, TEXT NULL, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, VARCHAR(255) NULL

executable field names = identifier, name, version, runtimeEnvironmentName, arguments, outputFiles, executableFile, comment, created, lastModified, inputFiles
executable field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), TEXT, DATETIME, DATETIME, VARCHAR(255)

runtimeEnvironment field names = identifier, name, computingSystem, certificate, url, initLines, depends, provides, created, lastModified
runtimeEnvironment field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), TEXT, VARCHAR(255), TEXT, TEXT, TEXT, DATETIME, DATETIME

#--------------------------------------------------------------------
[Regional_DB]
#
# Regional dataset and file catalog.
# Authentication is done with the grid certificate (user/password empty).
# Read access to non-authorized users is typically granted with user
# 'dq2user' and password 'dqpwd'.
#

class = gridpilot.dbplugins.mysql.MySQLDatabase
driver = org.gjt.mm.mysql.Driver
database = jdbc:mysql://www.gridpilot.dk:3306/file_catalog

parameters = driver database user password

description = Regional file catalog
enabled = no

# JDBC connect timeouts in milliseconds; 0 means no timeout
connect timeout = 0
# JDBC socket timeouts in milliseconds; 0 means no timeout
socket timeout = 0

# Whether or not to cache search results locally
cache search results = yes

default dataset fields = name outputLocation executableName identifier
hidden dataset fields = metaData
default file fields = dsname lfname pfname guid
file identifier = guid
file name = lfname
file dataset reference = name dsname

# NOTICE: semi-colon will be replaced with comma after parsing the fields

dataset field names = identifier,                   name,                                     executableName,    executableVersion, metaData,  runNumber,    totalFiles,   totalEvents,  created,  lastModified, inputDataset,      inputDB,           outputLocation
dataset field types = VARCHAR(255) NOT NULL UNIQUE, VARCHAR(255) NOT NULL UNIQUE PRIMARY KEY, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, INT(20) NULL, INT(20) NULL, INT(20) NULL, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL

# This is to have an explicit file catalog

pfns field = pfname
bytes field = fsize
checksum field = md5sum

file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid

t_lfn field names = lfname, guid
t_lfn field types = VARCHAR(255), VARCHAR(40) PRIMARY KEY

t_pfn field names = pfname, guid, filetype
t_pfn field types = VARCHAR(255), VARCHAR(40) PRIMARY KEY, VARCHAR(255) DEFAULT NULL

t_meta field names = guid, md5sum, fsize, lastmodified, archival, dsname
t_meta field types = VARCHAR(40) PRIMARY KEY, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, VARCHAR(255)

#--------------------------------------------------------------------
[GP_DB]
#
# Minimal shared dataset/job/file catalog for public testing.
# All certificates from known CAs are granted r/w access.
#

class = gridpilot.dbplugins.mysql.MySQLDatabase
driver = org.gjt.mm.mysql.Driver
database = jdbc:mysql://db.gridpilot.dk:3306/gridpilot

parameters = driver database user password

description = Public database provided at gridpilot.dk
enabled = no

# JDBC connect timeouts in milliseconds; 0 means no timeout
connect timeout = 0
# JDBC socket timeouts in milliseconds; 0 means no timeout
socket timeout = 0

# Whether or not to cache search results locally
cache search results = no

default dataset fields = name outputLocation executableName identifier
hidden dataset fields = metaData
default jobDefinition fields = name status
default file fields = dsname lfname pfname guid
file identifier = guid
file name = lfname
file dataset reference = name dsname
pfns field = pfname
bytes field = fsize
checksum field = md5sum

# NOTICE: semi-colon will be replaced with comma after parsing the fields

dataset field names = identifier,                   name,                                     executableName,    executableVersion, metaData,  runNumber,    totalFiles,   totalEvents,  created,  lastModified, inputDataset,      inputDB,           outputLocation
dataset field types = VARCHAR(255) NOT NULL UNIQUE, VARCHAR(255) NOT NULL UNIQUE PRIMARY KEY, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, INT(20) NULL, INT(20) NULL, INT(20) NULL, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL

jobDefinition field names = identifier, datasetName, name, guid, number, eventMin, eventMax, nEvents, outputFileBytes, outputFileChecksum, cpuSeconds, status, userInfo, inputFileURLs, executableParameters, outFileMapping, host, stdoutDest, stderrDest, created, lastModified, jobID, outTmp, errTmp, validationResult, computingSystem, csStatus, metaData, depJobs
jobDefinition field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), VARCHAR(255), INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, VARCHAR(255), INT(16) NULL, ENUM('Defined'; 'Submitted'; 'Validated'; 'Failed'; 'Undecided'; 'Aborted') NULL, VARCHAR(255), TEXT, VARCHAR(255), VARCHAR(2048), VARCHAR(255), VARCHAR(255), VARCHAR(255), DATETIME, DATETIME, VARCHAR(255) NULL, VARCHAR(1024) NULL, VARCHAR(1024) NULL, TEXT NULL, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, VARCHAR(255) NULL

executable field names = identifier, name, version, runtimeEnvironmentName, arguments, outputFiles, executableFile, comment, created, lastModified, inputFiles
executable field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), TEXT, DATETIME, DATETIME, VARCHAR(255)

runtimeEnvironment field names = identifier, name, computingSystem, certificate, url, initLines, depends, provides, created, lastModified
runtimeEnvironment field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), TEXT, VARCHAR(255), TEXT, TEXT, TEXT, DATETIME, DATETIME

# This is to have an explicit file catalog

file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid
pfns field = pfname

t_lfn field names = lfname, guid
t_lfn field types = VARCHAR(255), VARCHAR(40) PRIMARY KEY

t_pfn field names = pfname, guid, filetype
t_pfn field types = VARCHAR(255), VARCHAR(40) PRIMARY KEY, VARCHAR(255) DEFAULT NULL

t_meta field names = guid, md5sum, fsize, lastmodified, archival, dsname
t_meta field types = VARCHAR(40) PRIMARY KEY, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, VARCHAR(255)

#--------------------------------------------------------------------
[ATLAS]
#
# Central ATLAS dataset and file catalog.
# The dataset catalog is the DQ2 server at CERN.
# The file catalog is a combination of the DQ2 server
# at CERN and the LFC and MySQL catalogs registered as
# sites in the TiersOfAtlas file at CERN.
#
class = gridpilot.dbplugins.atlas.ATLASDatabase

parameters = 

description = File catalog of the ATLAS experiment at CERN
enabled = no

# Whether or not to cache search results locally
cache search results = yes

# The "home" LFC or MySQL server (its alias from TOA).
# For a MySQL server, write access may be obtained by not specifying any
# user:password in the URL. In this case the grid certificate is used for authentication.
home site = # NDGFT1DISK # FZKDISK
# If the home site is an LFC site, the path under which new datasets should be
# registered should be specified. Notice that it will be prepended with /grid/atlas.
user path = /users/MyName
# When a file has several physical replicas, try these locations first.
preferred sites = NDGF-T1_SCRATCHDISK NDGFT1DISK CSCS FZKDISK LYONDISK CERNCAF CERNPROD
# Sites we know are not responding.
ignored sites = CERN.* INFN.*
# File catalog timeout in miliseconds
file catalog timeout = 10000
default dataset fields = dsn incomplete complete vuid
dataset identifier = vuid
dataset name = dsn
#NOTICE: because of DQ2 limitations, if you want to be able to download/replicate files this list MUST be the full list, dsn lfn pfns guid
default file fields = dsn lfn catalogs pfns guid bytes checksum
file identifier = guid
file name = lfn
file dataset reference = dsn dsn
pfns field = pfns
bytes field = bytes
checksum field = checksum
# URL of the file used to resolve site names to file catalog servers.
# A path to a local file may be given as second argument.
# In this case the URL is cached across GridPilot sessions.
tiers of atlas = http://atlas.web.cern.ch/Atlas/GROUPS/DATABASE/project/ddm/releases/TiersOfATLASCache.py file:~/GridPilot/TiersOfATLASCache.txt
# If this is set to true, files will be attempted deleted on
# all physical locations and on the home catalog server and the home
# catalog server will be de-registered in DQ, even if other
# catalog sites are registered in DQ than the home catalog or if there
# is no home catalog set.
force file deletion = no

## DQ2 parameters
DQ2 server = atlddmcat.cern.ch
DQ2 port = 80
DQ2 secure port = 443
DQ2 path = /dq2

#####################################################################
[Computing systems]
#
# Backends for executing computing jobs.
#

Systems = Fork VMFork SSH_Pool EC2 GridFactory NG GLite # SSH  EC2Soap EC2Alt

# Maximum number of simultaneous submission threads.
# Notice that these threads may upload files via SSH.
# Can be overridden under each computing system.
max simultaneous submissions = 3
# Maximum total number of running jobs per computing system.
# When this is reached, queued jobs will not be started until
# running jobs end (on this computing system).
# Notice that this can also be set in the sub-section for GridPilot
# in each individual computing system section.
# The maximum number of running jobs per enabled computing system.
# Can be overridden under each computing system.
max simultaneous running = 10
# The maximum number of preprocessing threads for each computing system.
# Each thread will typically upload input file(s) for a job to the
# remote computing resource.
max simultaneous preprocessing = 10
# Delay between starting submissions (in milliseconds).
time between submissions = 4000
# Number of times to try and find a host for a job. This means that each job
# will sit at most 'submit retries' * 'time between submissions' in GridPilots
# preprocessing queue. 
submit retries = 20
# Whether to start submissions in the order they appear in the table
# or in random order.
randomized submission = no
# Delay between starting validation (in milliseconds)
delay before validation = 3000
# Maximum number of simultaneous validation threads.
max simultaneous validating = 3
# Maximum number of simultaneous post-processing threads.
# Notice that these threads may download output files via SSH.
max simultaneous post-processing = 3
# Space-separated list of strings. Lines  in stdout containing any of these will
# cause jobs to be considered failed.
validation error patterns =
# Space-separated list of strings. Lines  in stderr containing any of these will be
# ignored when validing jobs.
validation error antipatterns = 

#--------------------------------------------------------------------
[Fork]
#
# Run jobs on the local computer.
#

## Sub-section for GridPilot
enabled = no
host = localhost
user =
password =
class = gridpilot.csplugins.fork.ForkComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking)
max jobs by update = 10
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 1
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 1

## Sub-section for this plug-in
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Optional list of shell protocols and commands for getting/putting remote input/output files.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands =
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments =
# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DBs to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local

# Certificate used by submitters to encrypt their
# proxy certificate+key to the GridPilot picking up the job.
# Only needed to pick up jobs.
# NOTICE: the certificate should NOT include a key!
public certificate = ~/.globus/usercert.pem

#--------------------------------------------------------------------
[VMFork]
#
# Run jobs inside virtual machine on the local computer.
#

## Sub-section for GridPilot
enabled = yes
host = localhost
user =
password =
class = gridpilot.csplugins.vmfork.VMForkComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking)
max jobs by update = 10
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 1
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 1
# The maximum number of preprocessing threads.
max simultaneous preprocessing = 1

## Sub-section for this plug-in
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Directory for downloaded input files.
file cache directory = ~/GridPilot/jobs
# In which DBs to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local
# Maximum number of running  jobs per host (one number in total -
# valid for all hosts). If empty, 1 will be assumed.
max running jobs per host = 1
# Number per host of job(s) preprocessing while other job(s) are running
# (one number in total - valid for all hosts). If empty, 1 will be assumed.
max preprocessing jobs per host = 1
# Whether or not to force running jobs inside a virtual machine. If set
# to false, jobs will run directly on the local machine if possible
# (if all required RTEs can be installed).
enforce virtualization = yes
# The amount of RAM (in megabytes) to assign to the virtual machine.
default ram per vm = 512
# Command to start a terminal running a secure shell. This command will be
# given the port number as first argument and user@host as second argument.
ssh command = # /usr/bin/konsole -e /usr/bin/ssh -X -p
# Time to wait (in seconds) for a VM to boot. Notice, that for a first boot
# this includes download time of all required RTEs and typically also 
# duplication of the disk image.
boot timeout = 700
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stdout of jobs
stdout exclude words = VERBOSE DEBUG INFO 'so far'
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stderr of jobs
stderr exclude words = install_scripts

#--------------------------------------------------------------------
[GridFactory]
#
# Submit jobs to a GridPilot database somewhere,
# where they will be picked up by other GridPilots.
#

## Sub-Section for GridPilot
enabled = no
host = localhost
user = 
password =
class = gridpilot.csplugins.gridfactory.GridFactoryComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 10
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be submitted until running jobs end.
max simultaneous running = 100

## Sub-Section for this plug-in
# Where to submit the jobs.
submission urls = https://www.gridfactory.org/gridfactory/jobs/
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local
# Local directory to keep script and stdout/stderr
working directory = ~/GridPilot/jobs

# Space separated list of certificate subjects or URLs (http, ftp, gsiftp, srm, file)
# of files containing certificate subjects, e.g. 'http://www.chipp.ch/vo/chipp.txt'.
# Each list entry must be enclosed in single-quotes.
# The owner of a certificates with one these subjects will be allowed
# to run jobs, if the CA that issued the certificate is on the list of ca certificates.
# If empty, any provider will be allowed to run my jobs.
allowed subjects =
# Whether jobs should run on Windows (or Linux/UNIX).
on windows = false
# Whether or not jobs should be forced to run inside virtual machines.
virtualize = false
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stdout of jobs
stdout exclude words = VERBOSE DEBUG INFO 'so far'
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stderr of jobs
stderr exclude words = install_scripts

#--------------------------------------------------------------------
[SSH]
#
# Run jobs on remote computer.
#

## Sub-section for GridPilot
enabled = no
# Notice: if you use lxplus.cern.ch you disconnect, reconnect and find you jobs again,
# since you will most likely be on a different machine.
host = lxplus203.cern.ch
user = 
password =
class = gridpilot.csplugins.fork.ForkComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 1
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 1

## Sub-Section for this plug-in
# Optionally login with a private key. This will be tried only once, then
# normal login with password will be tried
ssh key file = 
ssh key passphrase = 
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Optional commands for remote input files or output destination
# (castor://, ftp://, gsiftp://, ...), e.g. ngcp gsiftp://server/dir/file.root file.root.
# Optionally runtime environments providing these commands can be specified.
# Notice: to have file copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands =
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments =
# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local

#--------------------------------------------------------------------
[SSH_Pool]
#
# Run jobs on a pool of remote computers.
#

## Sub-section for GridPilot
enabled = no
# The main host, where runtime environments, etc. are present.
host = localhost
user = 
password =
class = gridpilot.csplugins.forkpool.ForkPoolComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 10

## Sub-Section for this plug-in
# Optionally login with a private key. This will be tried only once, then
# normal login with password will be tried
ssh key file = 
ssh key passphrase = 
# Additional hosts for running jobs
hosts = lxplus218.cern.ch lxplus219.cern.ch
# List of user names (one per host). If empty prompting will be done.
users = 
# List of passwords (one per host). If empty prompting will be done.
passwords =
# Maximum number of running  jobs per host (one number for each host).
# If empty, 1's will be assumed.
max running jobs per host =
# Number per host of job(s) preprocessing while other job(s) are running
# (one number for each host). If empty, 1's will be assumed.
max preprocessing jobs per host =
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Optional commands for remote input files or output destinations
# (castor://, ftp://, gsiftp://, ...), e.g. ngcp gsiftp://server/dir/file.root file.root.
# Optionally runtime environments providing this command can be specified.
# Notice: to have file copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands =
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments =
# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local

#--------------------------------------------------------------------
[EC2]
#
# Run jobs on a pool of virtual machines in the Amazon Elastic
# Compute Cloud.
#

## Sub-section for GridPilot
enabled = no
# host should just be localhost. It is used for manipulating local job
# information, etc.
host = localhost
# user should be left blank - we're on localhost
user = 
# password should be left blank - we're on localhost
password =
class = gridpilot.csplugins.ec2.EC2ComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 3
# The maximum number of preprocessing threads.
max simultaneous preprocessing = 3

## Sub-Section for this plug-in
# Number of running jobs per host
max running jobs per host = 1
# Number of preprocessing jobs per host
max preprocessing jobs per host = 1
# IP address of the server
server address = 
# Port the web service is running on
port number = 
# Whether to use HTTPS or HTTP
secure = yes
# Path to the web service
service path = 
# The access key id found on your AWS account web page
aws access key id =
# The secret access key found on your AWS account web page
aws secret access key =
# Fall-back AWS Machine Image (AMI) to use. If this is not set, jobs with
# OS requirements that cannot be met are not run (no machine is booted).
fallback ami id =
# The subnet from which ssh access to the AWS virtual machines will
# be granted. If left empty, 0.0.0.0/0 is used, i.e. access is granted from anywhere
ssh access subnet = 0.0.0.0/0
# Maximum number of virtual machines to be run
max machines = 1
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Command for remote input files or output destination
# e.g. s3_copy sss://bucket/dir/file.root file.root.
# This command will be executed by the job script itself.
# Optionally a runtime environment providing this command can be specified.
# Notice: to have file copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands = # sss s3_copy
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments = # UTIL/AWS-1.29
# RTE catalogs: these should be catalogs with AMIs (AMIPackages) providing
# software installations or depending on EBS software volumes (EBSSnapshotPackages).
# Notice that the TarPackages and ImagePackages from the global RTE catalog can
# also be installed on EC2.
runtime catalog URLs = sss://gridpilot/ec2_rtes.xml
# Prefix of AMI manifests. If specified, only manifests starting with this
# will be considered.
ami prefix =

# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local
# Command to start a terminal running a secure shell. This command will
# be given the full path of the SSH key as first argument and the host
# name as second argument.
ssh command = # /usr/bin/konsole -e /usr/bin/ssh -X -l root -i
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stdout of jobs
stdout exclude words = VERBOSE DEBUG INFO 'so far'
# Lines containing one of these words (or phrases enclosed with single quotes)
# will be filtered out from the stderr of jobs
stderr exclude words = install_scripts

#--------------------------------------------------------------------
[EC2Soap]
#
# Run jobs on a pool of virtual machines in the Amazon Elastic
# Compute Cloud.
#

## Sub-section for GridPilot
enabled = no
# host should just be localhost. It is used for manipulating local job
# information, etc.
host = localhost
# user should be left blank - we're on localhost
user =
# password should be left blank - we're on localhost
password =
class = gridpilot.csplugins.ec2soap.EC2SoapComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 10

## Sub-Section for this plug-in
# URL the EC2 service
service url = http://mayhem9.cs.ucsb.edu:8773/services/Eucalyptus # https://ec2.amazonaws.com # 
# The AWS Machine Image (AMI) to use
fallback ami id = emi-0D52023B # ami-2b5fba42 # 
# The subnet from which ssh access to the AWS virtual machines will
# be granted. If left empty, 0.0.0.0/0 is used, i.e. access is granted from anywhere
ssh access subnet = 0.0.0.0/0
# Maximum number of virtual machines to be run
max machines = 2
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Optional commands for remote input files or output destination
# (castor://, ftp://, gsiftp://, ...), e.g. ngcp gsiftp://server/dir/file.root file.root.
# Optionally runtime environments providing these commands can be specified.
# Notice: to have file copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands =
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments =
# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local
# Command to start a terminal running a secure shell. This command will
# be given the full path of the SSH key as first argument and the host
# name as second argument.
ssh command = 

#--------------------------------------------------------------------
[EC2Alt]
#
# Run jobs on a pool of virtual machines in the Amazon Elastic
# Compute Cloud.
#

## Sub-section for GridPilot
enabled = no
# host should just be localhost. It is used for manipulating local job
# information, etc.
host = localhost
# user should be left blank - we're on localhost
user =
# password should be left blank - we're on localhost
password =
class = gridpilot.csplugins.eucalyptus.EC2AltComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 10

## Sub-Section for this plug-in
# URL the EC2 service
service url = https://ec2.amazonaws.com
# The access key id found on your AWS account web page
aws access key id = 
# The secret access key found on your AWS account web page
aws secret access key = 
# The AWS Machine Image (AMI) to use
fallback ami id = ami-2b5fba42
# The subnet from which ssh access to the AWS virtual machines will
# be granted. If left empty, 0.0.0.0/0 is used, i.e. access is granted from anywhere
ssh access subnet = 0.0.0.0/0
# Maximum number of virtual machines to be run
max machines = 2
# Directory to 'cd' to before running job scripts.
working directory = ~/GridPilot/jobs
# Optional commands for remote input files or output destination
# (castor://, ftp://, gsiftp://, ...), e.g. ngcp gsiftp://server/dir/file.root file.root.
# Optionally runtime environments providing these commands can be specified.
# Notice: to have files copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
# Format: protocol1 command1 protocol2 command2 ...
remote copy commands =
# These RTE scripts will be sourced regardless of whether they are specified
# in the job record or not. Typically used to provide the 'remote copy commands'.
required runtime environments =
# Where to create a sample test executable. If not defined, none is created.
executable directory = ~/GridPilot/executables
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_Local
# Command to start a terminal running a secure shell. This command will
# be given the full path of the SSH key as first argument and the host
# name as second argument.
ssh command = 

#--------------------------------------------------------------------
[NG]
#
# Submit jobs to NorduGrid.
#

## Sub-section for GridPilot
enabled = no
class = gridpilot.csplugins.ng.NGComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 100

## Sub-section for this plug-in
# This is where scripts and stdout/stderr is kept on the *local* disk.
# Use / instead of \.
working directory = ~/GridPilot/jobs
# Where to write the runtime records.
runtime databases = My_DB_Local
# Whether or not to use the information system.
# If set to no, functionality is somewhat limited, but
# it should be possible to submit jobs to a specific cluster.
use information system = yes
# The GIIS information servers to query for clusters.
GIISes = ldap://index1.nordugrid.org:2135/Mds-Vo-name=nordugrid,o=grid # ldap://odin.switch.ch:2135/Mds-Vo-name=Switzerland,o=grid
# Explicitly chosen clusters. Space-separated list of CE host names. If this is set, GIIS servers will not be queried.
clusters =  lscf.nbi.dk # grid03.unige.ch lheppc50.unibe.ch lheppc10.unibe.ch nordugrid-lcg.projects.cscs.ch hypatia.uio.no hagrid.it.uu.se benedict.grid.aau.dk gateway01.dcsc.ku.dk interop.dcgc.dk morpheus.dcgc.dk
# Explicitly excluded clusters. Space-separated list of regular expressions.
excluded clusters = 
# Required CPU time in minutes.
cpu time = 10
# Required memory in megabytes
memory = 512
# Maximum number of retrying failed jobs.
max rerun = 1
# Extra XRSL
extra xrsl = #(count=8)

#--------------------------------------------------------------------
[GLite]
#
# Submit jobs to the EGEE grid.
#

## Sub-section for GridPilot
enabled = no
class = gridpilot.csplugins.glite.GLiteComputingSystem
# Maximum number of jobs whose status is checked by each thread
# (see max simultaneous checking).
max jobs by update = 1
# Maximum number of simultaneous submission threads submitting to this CS.
max simultaneous submissions = 3
# Maximum number of running jobs. When this is reached,
# queued jobs will not be started until running jobs end.
max simultaneous running = 100

## Sub-section for this plug-in
# This is where scripts and stdout/stderr is kept on the *local* disk.
# Use / instead of \.
working directory = ~/GridPilot/jobs
# Required CPU time in minutes.
cpu time = 180
# Required memory in megabytes
memory =
# Maximum number of retrying failed jobs on the node (ShallowRetryCount).
max rerun = 1
# The WMProxy service endpoint.
wmproxy url = https://wms211.cern.ch:7443/glite_wms_wmproxy_server # https://wms205.cern.ch:7443/glite_wms_wmproxy_server # https://wms217.cern.ch:7443/glite_wms_wmproxy_server
# The LB service endpoint - when left empty it is inferred from the above
lb url = # https://wms211.cern.ch:9003
# The BDII host.
bdii host = lcg-bdii.cern.ch
# Clusters to scan for RTEs. Leaving this empty will cause all clusters
# to be scanned - this may take a long time.
runtime clusters = ce-iep-grid.saske.sk # ce.cyf-kr.edu.pl # ce103.cern.ch # ce01-lcg.projects.cscs.ch ce01-lcg.projects.cscs.ch g03n02.pdc.kth.se
# Timeout in seconds when scanning each runtime cluster for RTEs
mds timeout = 40
# Explicitly chosen clusters to run jobs. Space-separated list of CE endpoints like e.g. ce-iep-grid.saske.sk:2119/jobmanager-lcgpbs-atlas. Regular expressions are possible.
clusters = # ce-iep-grid.saske.sk:2119/jobmanager-lcgpbs-atlas
# Explicitly excluded clusters. Space-separated list of regular expressions.
excluded clusters = 
# Space separated list of virtual organizations for which to setup RTEs.
runtime vos = atlas
# RTE tags to be used to label replacement rules for runtime environment scripts. Can be any strings.
runtime path tags = atlas_production_scr
# For each of above tags. Mapping of tag to actual setup scripts to be sourced.
# The first string must be a regular expression, the following strings must resolve to
# the script paths.
#atlas_production_scr = VO-atlas-production-(\d+\.\d+\.\d+)(\.*\d*).* \$VO_ATLAS_SW_DIR/software/$1/setup*.sh \$SITEROOT/AtlasProduction/$1$2/AtlasProductionRunTime/cmt/setup.sh
atlas_production_scr = VO-atlas-production-(\d+\.\d+\.\d+)(\.*\d*).* \$VO_ATLAS_SW_DIR/software/$1/setup.sh
# RTE tags to be used to label replacement rules for runtime environment names. Can be any strings.
runtime translation tags = atlas_production_rte
# For each of above tags. Mapping of tag to regular expression dublet.
atlas_production_rte = VO-atlas-production-(.*) APPS/HEP/ATLAS/ATLAS-$1
# Where to write the runtime records.
runtime databases = My_DB_Local

# This entry must be here for PreferencesPanel to work.
[end]
