########################################################################
# This is the configuration file of GridPilot
#
# Sections:
#
# - GridPilot : contains general parameters
# - File transfer systems : information about the file transfer systems
# - - For each system defined in File transfer systems, a section is required
# - Databases : information about the database connection
# - - For each system defined in Databases, a section is required
# - Computing Systems : contains the list of computing systems
# - - For each system defined in section Computing Systems, a section is required
#
# All tags are case insensitive, and a text after a # is a comment (but \# is allowed)
#
# Main author:
#
# - Frederik ORELLANA (frederik.orellana@cern.ch)
#
# Contributors:
#
# - Cyril TOPFEL (cyril.topfel@lhep.unibe.ch)
# - Marco NIINIMAKI (marko.niinimaki@cern.ch)
# - Luc GOOSSENS (luc.goossens@cern.ch)
# - Vandy BERTEN (vandy.berten@cern.ch)
#
########################################################################

[GridPilot]
# This name is only used for field in jobDefinition tables ONLY if
# no name can be obtained from grid certificate
user = firelord
# Path to images, certificates, about
resources = /resources/		
# Debug level ; 0 : all debugs are disabled, 3 : maximum.
# Notice that having a high debug level can have a big impact on performance
debug = 2

# Attributes always displayed when creating job definitions
job attributes = number name

# Inital panels (tabs) displayed
initial panels = transformation dataset

# File to store the history of the file browser
browser history file = ~/gridpilot_history.txt

# Number of file records to diplay on files tabs (with previous/next buttons)
# Use -1 to show all files
file rows = 500

# Web proxy settings
proxy host = 
proxy port =

# List of preferred files servers when down/uploading
preferred file servers = gsiftp://grid01.unige.ch gsiftp://grid00.unige.ch srm://se01-lcg.projects.cscs.ch *.dk *.de *.ch *.fr

# number of seconds before timeout of proxy when proxy will be renewed
proxy time left limit = 43200 # 12h
proxy time valid = 129600 # 36 h
key file = ~/.globus/userkey.pem
certificate file = ~/.globus/usercert.pem
grid proxy directory = ~/.globus
key password = 
# A comma separated list of fully qualified file or directory paths.
# If this is left blank, the default certificates shipped with GridPilot will be used
ca certificates = # ~/.globus/certificates, /etc/grid-security/certificates

# submissions
maximum simultaneous submissions = 3
time between submissions = 5000 # in ms
randomized submission = no

# transfers
maximum simultaneous transfers = 10
time between transfers = 500 # in ms
randomized transfers = no
# default URL when replicating
gridftp home url = ~

# updates
maximum simultaneous checking = 3
time between checks = 500 # in ms

# validation
delay before validation = 3000 # in ms
maximum simultaneous validating = 3

# timeouts (in seconds)
default timeout = 60
submit timeout = 60
updateStatus timeout = 60
killJob timeout = 60
clearOutputMapping timeout = 60
exit timeout = 60
getFullStatus timeout = 60
getCurrentOutputs timeout =  60
db timeout = 60000

#####################################################################
[File transfer systems]
#
# File transfer systems used for replicating files.
#

# These are the supported systems. The names must match the protol names.
# NOTICE: always put subsystems before high-level systems, that is,
# always put srm last.
Systems = gsiftp srm
# These ports must be inbound open in your firewall (comma-separated list)
globus tcp port range = 9001,9010
# Timeouts in seconds
copy retries = 0
copy retry timeout = 120

[gsiftp]
class = gridpilot.ftplugins.gsiftp.GSIFTPFileTransfer
# number of transfers whose status is checked by each thread (see maximum simultaneous transfers)
max transfers by update = 3

[srm]
class = gridpilot.ftplugins.srm.SRMFileTransfer
# Retries to get "Ready" on a submitted transfer, before timing out
submit check retries = 3
# Time between these retries in miliseconds
submit check sleep = 10000
# number of transfers whose status is checked by each thread (see maximum simultaneous transfers)
max transfers by update = 1

#####################################################################
[Databases]
#
# Databases used for storing runtime and transformation
# informations as well as file and job information.
#

# NOTICE: use ONLY ONE local database at a time
Systems = My_DB_local My_DB_Geneva ATLAS_CH ATLAS

#--------------------------------------------------------------------
[My_DB_local]
#
# Minimal dataset/job/file catalog for personal production/analysis.
#
class = gridpilot.dbplugins.hsqldb.HSQLDBDatabase
driver = org.hsqldb.jdbcDriver
database = hsql://localhost/~/GridPilot/My_DB
user = sa
password = ""

parameters = driver database user password

default dataset fields = name runNumber identifier
hidden dataset fields = metaData
default jobDefinition fields = name status
default file fields = dsname lfname pfname guid
file identifier = guid
file name = lfname
file dataset reference = name dsname

dataset field names = identifier,                       name,                 transformationName, transformationVersion, metaData,         runNumber,   totalFiles,  totalEvents, created,  lastModified, inputDataset,     inputDB,          outputLocation
dataset field types = LONGVARCHAR NOT NULL PRIMARY KEY, LONGVARCHAR NOT NULL, LONGVARCHAR NULL,   LONGVARCHAR NULL,      LONGVARCHAR NULL, BIGINT NULL, BIGINT NULL, BIGINT NULL, DATETIME, DATETIME,     LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL

jobDefinition field names = identifier,                                           datasetName, name,        guid,        number, eventMin, eventMax, nEvents,  outputFileKilobytes, cpuSeconds, status,  userInfo,    inputFileNames, transPars,   outFileMapping, md5sum,      stdoutDest,  stderrDest,  created,  lastModified, jobID,        outTmp,       errTmp,       validationResult, computingSystem
jobDefinition field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, INT,    INT,      INT,      INT,      INT NULL,            INT NULL,   VARCHAR, LONGVARCHAR, LONGVARCHAR,    LONGVARCHAR, LONGVARCHAR,    LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME,     VARCHAR NULL, VARCHAR NULL, VARCHAR NULL, LONGVARCHAR NULL, VARCHAR NULL

transformation field names = identifier, name, version, runtimeEnvironmentName, arguments, outputFiles, script, comment, created, lastModified, inputFiles
transformation field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, VARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME, LONGVARCHAR

runtimeEnvironment field names = identifier, name, computingSystem, certificate, url, initLines, created, lastModified
runtimeEnvironment field types = INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, LONGVARCHAR, DATETIME, DATETIME

# This is to have an explicit file catalog

file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid

t_lfn field names = lfname, guid
t_lfn field types = LONGVARCHAR, VARCHAR NULL

t_pfn field names = pfname, guid, filetype
t_pfn field types = LONGVARCHAR, VARCHAR NULL, LONGVARCHAR NULL

t_meta field names = guid, md5sum, fsize, lastmodified, archival, dsname
t_meta field types = VARCHAR, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR NULL, LONGVARCHAR, VARCHAR

#--------------------------------------------------------------------
[My_DB_Geneva]
#
# Minimal dataset/job catalog for personal production/analysis
# The database and user name are deduced from the user certificate.
# The authentication is also done with the user certificate.
# A explicit file catalog should not be needed.
#
class = gridpilot.dbplugins.mysql.MySQLDatabase
driver = org.gjt.mm.mysql.Driver
database = jdbc:mysql://grid01.unige.ch:3306/

parameters = driver database user password

# JDBC timeouts in milliseconds; 0 means no timeout
connect timeout = 0
socket timeout = 0

default dataset fields = name runNumber identifier
hidden dataset fields = metaData
default jobDefinition fields = name status
default file fields = name datasetName url

file name = fileName

# NOTICE: semi-colon will be replaced with comma after parsing the fields

dataset field names = identifier,                                      name,                         transformationName, transformationVersion, metaData,  runNumber,    totalFiles,   totalEvents,  created,  lastModified, inputDataset,      inputDB,           outputLocation
dataset field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255) NOT NULL UNIQUE, VARCHAR(255) NULL,  VARCHAR(255) NULL,     TEXT NULL, INT(20) NULL, INT(20) NULL, INT(20) NULL, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL

jobDefinition field names = identifier, datasetName, name, guid, number, eventMin, eventMax, nEvents, outputFileKilobytes, cpuSeconds, status, userInfo, inputFileNames, transPars, outFileMapping, md5sum, stdoutDest, stderrDest, created, lastModified, jobID, outTmp, errTmp, validationResult, computingSystem
jobDefinition field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), VARCHAR(255), INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, INT(16) NULL, ENUM('Defined'; 'Submitted'; 'Validated'; 'Failed'; 'Undecided'; 'Aborted') NULL, VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(2048), VARCHAR(55), VARCHAR(255), VARCHAR(255), DATETIME, DATETIME, VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL, TEXT NULL, VARCHAR(255) NULL

transformation field names = identifier, name, version, runtimeEnvironmentName, arguments, outputFiles, script, comment, created, lastModified, inputFiles
transformation field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(55), VARCHAR(255), VARCHAR(255), VARCHAR(255), VARCHAR(255), TEXT, DATETIME, DATETIME, VARCHAR(255)

runtimeEnvironment field names = identifier, name, computingSystem, certificate, url, initLines, created, lastModified
runtimeEnvironment field types = INT(16) DEFAULT NULL AUTO_INCREMENT PRIMARY KEY, VARCHAR(255), VARCHAR(255), TEXT, VARCHAR(255), TEXT, DATETIME, DATETIME

#--------------------------------------------------------------------
[ATLAS_CH]
#
# Central Swiss dataset and file catalog.
# The (MySQL) database is hosted on a server at the
# the University of Geneva. Authentication is done with the grid
# certificate (user/password empty).
# Read access to non-Swiss-VO users can be granted with user
# 'dq2user' and password 'dqpwd'.
#
class = gridpilot.dbplugins.mysql.MySQLDatabase
driver = org.gjt.mm.mysql.Driver
database = jdbc:mysql://grid01.unige.ch:3306/atlas_ch

# JDBC timeouts in milliseconds; 0 means no timeout
connect timeout = 0
socket timeout = 0

parameters = driver database user password

default dataset fields = name runNumber identifier
hidden dataset fields = metaData
default file fields = dsname lfname pfname guid
hidden file fields = sync
file identifier = guid
file name = lfname
file dataset reference = name dsname

# NOTICE: semi-colon will be replaced with comma after parsing the fields

dataset field names = identifier,                        name,                         transformationName, transformationVersion, metaData,      runNumber,    totalFiles,   totalEvents,  created,  lastModified, inputDataset,      inputDB,           outputLocation
dataset field types = VARCHAR(255) NOT NULL PRIMARY KEY, VARCHAR(255) NOT NULL UNIQUE, VARCHAR(255) NULL,  VARCHAR(255) NULL,     TEXT NULL, INT(20) NULL, INT(20) NULL, INT(20) NULL, DATETIME, DATETIME,     VARCHAR(255) NULL, VARCHAR(255) NULL, VARCHAR(255) NULL

# This is to have an explicit file catalog

file field names = lfname, pfname, filetype, md5sum, fsize, lastmodified, archival, dsname, guid

t_lfn field names = lfname, guid
t_lfn field types = VARCHAR(250) PRIMARY KEY, VARCHAR(40) DEFAULT NULL

t_pfn field names = pfname, guid, filetype
t_pfn field types = VARCHAR(250) PRIMARY KEY, VARCHAR(40) DEFAULT NULL, VARCHAR(250) DEFAULT NULL

t_meta field names = guid, md5sum, fsize, lastmodified, archival, dsname, sync
t_meta field types = VARCHAR(40) PRIMARY KEY, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, BLOB DEFAULT NULL, VARCHAR(250), VARCHAR(40)

#--------------------------------------------------------------------
[ATLAS]
#
# Central ATLAS dataset and file catalog. The dataset catalog is the
# DQ2 server at CERN. The file catalog is a combination of the DQ2 server
# at CERN and the LFC and MySQL catalogs registered as sites in the
# TiersOfAtlas file at CERN. Writing file information is done by writing
# to the MySQL database registered as alias for the home LFC server.
# Authentication and authorization on this MySQL database is done via the
# grid certificate. The MySQL database is synchronized with the LFC database
# by a cron job running on the MySQL server.
#
class = gridpilot.dbplugins.atlas.ATLASDatabase

parameters = 

# DQ2 parameters
DQ2 server = atlddmpro.cern.ch
DQ2 port = 8000
DQ2 secure port = 8443
DQ2 path = /dq2

# The "home" LFC or MySQL server (its alias from TOA) and, for an LFC server,
# its optional MySQL URL alias; if the "home" server is an LFC server and
# no MySQL alias is given, there is only read access.
# If a MySQL alias is given, write access is obtained by not specifying any
# user:password in the URL. In this case the grid certificate is used for authentication.
#home site = FZKDISK mysql://dq2user:dqpwd@grid01.unige.ch:3306/localreplicas
home site = FZKDISK mysql://grid01.unige.ch:3306/localreplicas
preferred sites = CSCS FZKDISK LYONDISK CERNCAF CERNPROD
# File catalog timeout in miliseconds
file catalog timeout = 10000
default dataset fields = dsn incomplete complete vuid
dataset identifier = vuid
dataset name = dsn
# Notice: because of DQ2 limitations: if you want to be able to download/replicate files
#         this list MUST be the full list: dsn lfn pfns guid
default file fields = dsn lfn pfns guid
file identifier = guid
file name = lfn
file dataset reference = dsn dsn
# The file to resolve site names to file catalog servers
tiers of atlas = http://atlas.web.cern.ch/Atlas/GROUPS/DATABASE/project/ddm/releases/TiersOfATLASCache.py
#tiers of atlas = file:~/GridPilot/TiersOfATLASCache.txt

#####################################################################
[Computing systems]
#
# Backends for executing computing jobs.
#

systems = FORK NG # SSH  # GPSS LSF@CERN

#--------------------------------------------------------------------
[FORK]
#
# Run jobs on the local computer.
#

## Sub-section for GridPilot
host = localhost
user =
password =
class = gridpilot.csplugins.fork.ForkComputingSystem
working directory = ~/GridPilot/jobs
# number of jobs whose status is checked by each thread (see maximum simultaneous checking)
max jobs by update = 10

## Sub-Section for this plug-in
shell = /bin/bash
# Directory with runtime setup scripts
runtime directory = ~/GridPilot/runtimeEnvironments
# Where to create a sample test transformation. If not defined, none is created.
transformation directory = ~/GridPilot/transformations
# In which DBs to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime databases = My_DB_local My_DB_Geneva

## Sub-section for picking up jobs from external database
# Certificate used by submitters to encrypt their
# proxy certificate+key to the GridPilot picking up
# the job. Only needed to pick up jobs.
# NOTICE: the certificate should NOT include a key!
#public certificate = C:\Documents and Settings\Frederik Orellana\.globus\usercert.pem
# Remote DB to announce runtime environments and
# from where to pick up jobs. 
# Only needed to pick up jobs.
#remote database = My_DB_Geneva

remote copy command = ngcp
required runtime environment = ARC

#--------------------------------------------------------------------
[GPSS]
#
# Submit jobs to a GridPilot database somewhere,
# where they will be picked up by other GridPilots.
#

## Sub-Section for GridPilot
host = grid01.unige.ch
user = root
password =
class = gridpilot.csplugins.gridpilot.GridPilotComputingSystem
working directory = ~/GridPilot
max jobs by update = 40

## Sub-Section for this plug-in
shell = /bin/bash
runtime directory = ~/GridPilot/runtimeEnvironments
# Where to write the jobDefinitions.
remote database = My_DB_Geneva

#--------------------------------------------------------------------
[SSH]
#
# Run jobs on remote computer.
#

## Sub-section for GridPilot
# Notice: if you use lxplus.cern.ch you disconnect, reconnect and find you jobs again,
# since you will most likely be on a different machine.
host = lxplus070.cern.ch
user = 
password =
class = gridpilot.csplugins.fork.ForkComputingSystem
working directory = ~/GridPilot/jobs
max jobs by update = 1

## Sub-Section for this plug-in
shell = /bin/bash
# Directory with runtime setup scripts
runtime directory = ~/GridPilot/runtimeEnvironments
# Where to create a sample test transformation. If not defined, none is created.
transformation directory = ~/GridPilot/transformations
# In which DB to write the runtime environment records. If not specified,
# runtime environment records must be defined by hand.
runtime database = My_DB_Geneva

# When using remote input files or output destination (castor://, ftp://, gsiftp://, ...)
# a command for getting/putting the files (e.g. ngcp gsiftp://server/dir/file.root file.root)
# and optionally a runtime environment providing this command should be specified.
# Notice: to have file copied from the local machine to the ssh host, specify
# input files as file://. If they are given as /dir/file or C:\dir\file, they
# are assumed to be on the server already.
remote copy command = ngcp
required runtime environment = ARC

#--------------------------------------------------------------------
[LSF@CERN]
#
# Submit jobs to the LSF batch system at CERN. The interaction is
# done via an intermediate remote shell on a server at CERN.
#

## Sub-section for GridPilot
host = lxplus.cern.ch
user = fjob
password = 
class = gridpilot.csplugins.lsf.LSFComputingSystem
working directory = ~/GridPilot
max jobs by update = 1

## Sub-Section for this plug-in
packageID = LSF@CERN
# Directory with runtime setup scripts
runtime directory = /afs/cern.ch/bla/bla
# Where to write the runtime records
runtime database = My_DB_local
# TODO: drop all these
shell = /usr/bin/env zsh
submission command = bsub -q 1nh
#submission command = bsub  -R type==LINUX6 -q prod400 -R "cpuf>1.5&&maxmem>500"
check command = bjobs
copy command = rfcp
remove command = rfrm
mkdir command = rfmkdir
kill command = bkill

#--------------------------------------------------------------------
[NG]
#
# Submit jobs to NorduGrid. All interaction is done in pure java.
#

## Sub-section for GridPilot
class = gridpilot.csplugins.ng.NGComputingSystem
max jobs by update = 1
# This is where scripts and stdout/stderr is kept on the *local* disk. Use / instead of \
working directory = ~/GridPilot/jobs

## Sub-Section for this plug-in
# Where to write the runtime records
runtime databases = My_DB_local My_DB_Geneva
use information system = yes
# The GIIS information servers to query for clusters
GIISes = ldap://odin.switch.ch:2135/Mds-Vo-name=Switzerland,o=grid # ldap://index1.nordugrid.org:2135/Mds-Vo-name=nordugrid,o=grid
# explicitly choose clusters. If this is set, GIIS servers will not be queried.
clusters = grid00.unige.ch # lheppc50.unibe.ch lheppc10.unibe.ch nordugrid-lcg.projects.cscs.ch hypatia.uio.no hagrid.it.uu.se benedict.grid.aau.dk gateway01.dcsc.ku.dk interop.dcgc.dk morpheus.dcgc.dk # grid01.unige.ch nordugrid.unibe.ch
# Required CPU time in minutes.
cpu time = 1800 #10 # 
shell = /bin/sh

